{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMMyerPAsNz2"
   },
   "source": [
    "# ORF307 Homework 3 {-}\n",
    "Due: Friday, Feburary 26, 2021 9:00 pm ET\n",
    "\n",
    "- Please export your code with output as pdf.\n",
    "- If there is any additional answers, please combine them as **ONE** pdf file before submitting to the Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPoBdTsRsTkE"
   },
   "source": [
    "# Q1 Recursive least squares {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nXLxWyas2A5"
   },
   "source": [
    "In some applications of least squares the rows of the coefficient matrix $A$ become available (or are added) sequentially, and we wish to solve the resulting family of growing least squares problems. Define the $k \\times n$ matrices and $k$-vectors\n",
    "$$\n",
    "A^{(k)}= \n",
    "\\begin{bmatrix}\n",
    "a_1^T\\\\\n",
    "\\vdots\\\\\n",
    "a_k^T\n",
    "\\end{bmatrix}=A_{1:k, 1:n}, \\qquad\n",
    "b^{(k)}=\n",
    "\\begin{bmatrix}\n",
    "b_1\\\\\n",
    "\\vdots\\\\\n",
    "b_k\n",
    "\\end{bmatrix}=b_{1:k},\n",
    "$$\n",
    "for $k = 1, \\ldots, m$. We wish to compute $x^{\\star(k)}$, for $k = n, n + 1, \\ldots, m$, where $x^{\\star(k)}$ is the least squares approximate solution of $A^{(k)}x = b^{(k)}$.\n",
    "\n",
    "We will assume that the columns of $A^{(n)}$ are linearly independent and that $m$ is much larger than $n$, i.e., $m \\gg n$. A naive method to solve this sequence of problem applies factor-solve steps at each iteration to compute $x^{\\star(k)}$ in $2kn^2$ flops, so the total cost for $k=n,\\dots,m$ is\n",
    "$$\n",
    "\\sum_{k=n}^{m}2kn^2 = \\left(\\sum_{k=n}^{m}k\\right)(2n^2) = \\left(\\frac{m^2 - n^2 + m + n}{2}\\right)(2n^2) \\approx m^2 n^2\\quad \\mbox{flops}.\n",
    "$$\n",
    "\n",
    "We can reduce the computations with a simple trick that allows us to compute $x^{\\star(k)}$ for $k=n,\\dots,m$ much more efficiently, with a cost growing linearly with $m$. In addition, this method requires memory storage of $n^2$ elements, independently from $m$. Define\n",
    "\n",
    "$$\n",
    "G^{(k)}=(A^{(k)})^{T}A^{(k)},\\quad\\mbox{and}\\quad h^{(k)}=(A^{(k)})^T b^{(k)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwrWcUfls4Ur"
   },
   "source": [
    "(a) Show that $(G^{(k)}) x^{\\star(k)} = h^{(k)}$ for $k=n, \\ldots, m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI1M8buDs6yZ"
   },
   "source": [
    "(b) Show that $G^{(k+1)}=G^{(k)} + a_{k+1}a_{k+1}^T$ and $h^{(k+1)} = h^{(k)} + b_ka_k$ for $k=1, \\ldots, m-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqDJB04stCX5"
   },
   "source": [
    "(c) *Recursive least squares method.* Consider the following algorithm, called *recursive least squares*. For $k=n,\\dots,m$ compute $G^{(k+1)}$ and $h^{(k+1)}$ using (b). Then, solve the $k$th least squares problem using (a) to obtain $x^{\\star(k)}$. Explain how we can use the *matrix inversion lemma* from HW2 to solve each iteration $k$ and work out the total flop count by keeping only the leading terms. Compare it with the naive approach.\n",
    "\n",
    "*Note.* You can neglect the cost of first computing $G^{(n)}$ and $h^{(n)}$, which should be negligible in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJpLu3dBsWPP"
   },
   "source": [
    "# Q2 Robust approximate solution of linear equations {-}\n",
    "We wish to solve the square set of $n$\n",
    "linear equations $Ax = b$ for the $n$-vector $x$. If $A$ is invertible the solution is $x = A^{-1} b$\n",
    "\n",
    "In this exercise we address an issue that comes up frequently: We don’t know $A$ exactly.\n",
    "One simple method is to just choose a typical value of A and use it. Another method, which we explore here, takes into account the variation in the matrix $A$. We find a set of $K$ versions of $A$, and denote them as $A\n",
    "^{(1)}, . . . , A^{(K)}$\n",
    ". (These could be found by measuring\n",
    "the matrix $A$ at different times, for example.) Then, we choose $x$ so as to minimize\n",
    "$$\n",
    "\\|A^{(1)} x - b\\|_2 + ... + \\|A^{(K)} x - b\\|_2,\n",
    "$$\n",
    "the sum of the squares of residuals obtained with the $K$ versions of $A$. This choice of $x$,\n",
    "which we denote $x^{rob}$, is called a robust (approximate) solution. Give a formula for $x^{\\rm rob}$, in\n",
    "terms of $A\n",
    "^{(1)}, . . . , A^{(K)}$ and $b$. (You can assume that a matrix you construct has linearly\n",
    "independent columns.) Verify that for $K = 1$ your formula reduces to $x^{\\rm rob} = (A^{(1)})^{-1} b$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pk0L8VqNsXas"
   },
   "source": [
    "# Q3 Least norm polynomial interpolation. {-}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACTY2zpRwoS1"
   },
   "source": [
    "(a) Interpolation of polynomial values and derivatives. The $5$-vector $c$ represents the coefficients of a quartic polynomial $p(x) = c_1 +c_2 x + c_3 x^2 + c_4 x^3 + c_5 x^4$\n",
    ". Express the conditions \n",
    "$$p(0) = 0,\\quad p'(0) = 0, \\quad p(1) = 1, \\quad p'(1) = 0,$$ \n",
    "as a set of linear equations of the form $Ac = b$. Is the system of equations underdetermined, over-determined, or square?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnfuHA8QwpqP"
   },
   "source": [
    "(b) Find the polynomial\n",
    "of degree $4$ that satisfies the interpolation conditions from part (a), and minimizes the sum of the squares of its coefficients. Plot it, to verify that if satisfies the interpolation\n",
    "conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urhRskCisY3K"
   },
   "source": [
    "# Q4 Linear Quadratic Control {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7Lf6OHoXVmV"
   },
   "source": [
    "We consider a time-varying linear dynamical system with state $n$-vector $x_t$ and\n",
    "input $m$-vector $u_t$, with dynamics equations\n",
    "$$x_{t+1} = A_t x_t + B_t u_t, \\quad t = 1, 2, \\dots. $$\n",
    "The system has an output, the $p$-vector $y_t$, given by\n",
    "$$y_t = C_t x_t, \\quad t = 1, 2,\\dots. $$\n",
    "Usually, $m \\leq n$ and $p \\leq n$, i.e., there are fewer inputs and outputs than states.\n",
    "In control applications, the input $u_t$ represents quantities that we can choose or manipulate, like control surface deflections or engine thrust on an airplane. The state $x_t$, input $u_t$, and output $y_t$ typically represent deviations from some standard or desired operating condition, for example, the deviation of aircraft speed and altitude from the desired values. For this reason it is desirable to have $x_t$, $y_t$, and\n",
    "$u_t$ small.\n",
    "Linear quadratic control refers to the problem of choosing the input and state\n",
    "sequences, over a time period $t = 1, \\dots , T$, so as to minimize a sum of squares objective, subject to the dynamics equations \n",
    "$$x_{t+1} = A_t x_t + B_t u_t, \\quad t=1, 2,\\dots$$\n",
    "the output equations \n",
    "$$y_t = C_t x_t , \\quad t=1, 2, \\dots,$$\n",
    "and additional linear equality constraints. In ‘linear quadratic’, ‘linear’ refers to\n",
    "the linear dynamics, and ‘quadratic’ refers to the objective function, which is a\n",
    "sum of squares.\n",
    "Most control problems include an initial state constraint, which has the form\n",
    "$x_1 = x^{\\rm init}$, where $x^{\\rm init}$ is a given initial state. \n",
    "Some control problems also include a final state constraint $x_T = x^{\\rm des}$, where $x^{\\rm des}$ is a given (‘desired’) final (also called\n",
    "terminal or target) state.\n",
    "\n",
    "The objective function has the form $J = J_{\\rm output} + \\rho J_{\\rm input}$, where\n",
    "$J_{\\rm output} = \\|y_1\\|^2 + \\dots + \\|y_T\\|^2 = \\|C_1 x_1\\|^2 + \\dots + \\|C_T x_T\\|^2$,\n",
    "$J_{\\rm input} = \\|u_1\\|^2 + \\dots + \\|u_{T-1}\\|^2$\n",
    ".\n",
    "The positive parameter $\\rho$ weights the input objective $J_{\\rm input}$ relative to the output objective $J_{\\rm output}$.  \n",
    "\n",
    "Thus, the linear quadratic control problem is \n",
    "$$\n",
    "\\begin{array}{ll} \\mbox{minimize} & J_{\\rm output} + \\rho J_{\\rm input} \\\\ \n",
    "\\mbox{subject to} &  x_{t+1} = A_t x_t + B_t u_t, \\quad t=1, 2, \\dots \\\\\n",
    "& x_1 = x^{\\rm init}, x_T = x^{\\rm des}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47E93eBafbk5"
   },
   "source": [
    "We can solve this linear quadratic control problem by setting it up as a big linearly constrained least squares problem. We define the vector $z$ of all these variables, stacked:\n",
    "$z = (x_1, ..., x_T, u_1, ..., u_{T-1})$. The dimension of $z$ is $T n + (T-1)m$. The control objective can be expressed as\n",
    "$\\| \\tilde{A} z - \\tilde{b} \\|^2,$\n",
    "where $\\tilde{b} = 0$ and $\\tilde{A}$ is the block diagonal matrix\n",
    "$$\n",
    "\\tilde{A} = \n",
    "\\left[\\begin{array}{cccc|ccc}\n",
    "C_1 & & & & & &\\\\\n",
    "& C_2 & & & & &\\\\\n",
    "& & \\ddots & & & &\\\\\n",
    "& & & C_T & & &\\\\\n",
    "\\hline\n",
    "& & & & \\sqrt{\\rho}I & &\\\\\n",
    "& & & & & \\ddots &\\\\\n",
    "& & & & & & \\sqrt{\\rho}I\\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "In this matrix, (block) entries not shown are zero, and the identity matrices in the lower right corner have dimension $m$. The lines in the matrix delineate the\n",
    "portions related to the states and the inputs. The dynamics constraints, and the initial and final state constraints, can be expressed as $\\tilde{C} z = \\tilde{d}$, with\n",
    "$$\n",
    "\\tilde{C} = \n",
    "\\left[\\begin{array}{ccccc|cccc}\n",
    "A_1 & -I & & & & B_1 & & &\\\\\n",
    "& A_2 & -I & & & & B_2 & &\\\\\n",
    "& & \\ddots  & \\ddots & & & & \\ddots &\\\\\n",
    "& & & A_{T-1} & -I & & & & B_{T-1}\\\\\n",
    "\\hline\n",
    "I & & & & & & & &\\\\\n",
    "& & & & I &  & & & \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "where (block) entries not shown are zero. The vertical line separates the portions\n",
    "of the matrix associated with the states and the inputs, and the horizontal lines\n",
    "separate the dynamics equations and the initial and final state constraints.\n",
    "Finally, vector\n",
    "$$d =(0, 0, \\dots, 0, x^{\\rm init}, x^{\\rm des})$$\n",
    "has a length of $n(T-1) + 2$.\n",
    "\n",
    "The solution $z^\\star$ of the constrained least squares problem\n",
    "$$\n",
    "\\begin{array}{ll} \\mbox{minimize} & \\|\\tilde{A}z - \\tilde{b}\\|^2 \\\\ \n",
    "\\mbox{subject to} &  \\tilde{C} z = \\tilde{d}\n",
    "\\end{array}\n",
    "$$\n",
    "gives us the optimal input trajectory and the associated optimal state (and output)\n",
    "trajectory. The solution $z^\\star$ is a linear function of $\\tilde{b}$ and $\\tilde{d}$; since here $\\tilde{b} = 0$, it is a\n",
    "linear function of $x^{\\rm init}$ and $x^{\\rm des}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRSUyJfK6XDf"
   },
   "source": [
    "**State feedback control of the longitudinal motions of a Boeing 747 aircraft.** In this exercise we consider the control of the longitudinal motions of a Boeing 747 aircraft in steady level flight, at an altitude of 40000 ft, and speed 774 ft/s, which is 528 MPH or 460 knots, around Mach 0.8 at that altitude. Longitudinal means that we consider climb rate and speed, but not turning or rolling motions. For modest deviations from these steady state or trim conditions, the dynamics is given by the linear dynamical system $x_{t+1} = A x_t + B u_t$, with \n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "0.99 & 0.03 & -0.02 & -0.32 \\\\\n",
    "0.01 & 0.47 & 4.70 & 0.00 \\\\\n",
    "0.02 & -0.06 & 0.40 & 0.00 \\\\\n",
    "0.01 & -0.04 & 0.72 & 0.99 \\\\\n",
    "\\end{bmatrix}\n",
    ",\\quad\n",
    "B = \\begin{bmatrix}\n",
    "0.01 & 0.99 \\\\\n",
    "-3.44 & 1.66 \\\\\n",
    "-0.83 & 0.44 \\\\\n",
    "-0.47 & 0.25 \\\\\n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WEzKfVbm7D6R"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[.99, .03, -.02, -.32], \n",
    "              [.01, .47, 4.7, 0], \n",
    "              [.02, -.06, .4, 0], \n",
    "              [.01, -.04, .72, .99]])\n",
    "B = np.array([[.01, .99], \n",
    "              [-3.44, 1.66], \n",
    "              [-.83, .44], \n",
    "              [-.47, .25]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnVPxMMX8Ayb"
   },
   "source": [
    "with time unit one second. The state $4$-vector $x_t$ consists of deviations from the trim conditions of the following quantities.  \n",
    "- $(x_t)_1$ is the velocity along the airplane body axis, in ft/s, with forward motion\n",
    "positive. \n",
    "- $(x_t)_2$ is the velocity perpendicular to the body axis, in ft/s, with positive down. \n",
    "- $(x_t)_3$ is the angle of the body axis above horizontal, in units of 0.01 radian. \n",
    "- $(x_t)_4$ is the derivative of the angle of the body axis, called the pitch rate, in units of 0.01 radian/s.\n",
    "\n",
    "\n",
    "The input 2-vector ut (which we can control) consists of deviations from the trim conditions of the following quantities. \n",
    "- $(u_t)_1$ is the elevator (control surface) angle, in units of 0.01 radian.\n",
    "- $(u_t)_2$ is the engine thrust, in units of 10000 lbs. You do not need to know these details; \n",
    "\n",
    "we mention them only so you know what the entries of $x_t$ and $u_t$ mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgOM0syM9sJS"
   },
   "source": [
    "(a) Open loop trajectory. Simulate the motion of the Boeing 747 with initial condition\n",
    "$x_1 = e_4$, in open-loop (i.e., with $u_t = 0$). Plot the state variables over the time interval $t = 1, . . . , 120$ (two minutes). The oscillation you will see in the open-loop\n",
    "simulation is well known to pilots, and called the phugoid mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXc2_-Bv9zx_"
   },
   "source": [
    "(b) Linear quadratic control. Solve the linear quadratic control problem with $C = I$,\n",
    "$ρ = 100$, and $T = 100$, with initial state $x_1 = e_4$, and desired terminal state $x^{des} = 0$. Plot the state and input variables over $t = 1, \\dots , 120$. (For $t = 100, \\dots , 120$, the state and input variables are zero.). You may use the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wCDL9kSX_Ldr"
   },
   "outputs": [],
   "source": [
    "def KKT_matrix_rhs(A, b, C, d):\n",
    "    \"\"\" \n",
    "    returns the KKT matrix and the right hand side vector that describes the \n",
    "    linear system to solve the constrained least squares problem\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    p, n = C.shape\n",
    "\n",
    "    G = A.T @ A  # Gram matrix\n",
    "    KKT = np.block([[2*G, C.T], \n",
    "                    [C, np.zeros((p, p))]])\n",
    "    rhs = np.hstack([2*A.T @ b, d])\n",
    "    return KKT, rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9uCIWjXxJzJP"
   },
   "outputs": [],
   "source": [
    "def construct_tilde_matrices(A, B, C, x_init, x_des, T, rho):\n",
    "    \"\"\"\n",
    "    Construct A_tilde, b_tilde, c_tilde, d_tilde.\n",
    "    \"\"\"\n",
    "    n, m = B.shape\n",
    "    p = C.shape[0]\n",
    "\n",
    "    A_tilde = np.block([[np.kron(np.eye(T), C), np.zeros((p * T, m * (T-1)))], \n",
    "                        [np.zeros((m * (T - 1), n * T)), np.sqrt(rho) * np.eye(m * (T-1))]])\n",
    "\n",
    "    # construct btilde\n",
    "    b_tilde = np.zeros(p * T + m * (T - 1))\n",
    "\n",
    "    # construct Ctilde bit by bit \n",
    "    C_tilde11 = np.hstack([np.kron(np.eye(T-1),A), np.zeros((n*(T-1),n))]) \\\n",
    "        - np.hstack([np.zeros((n*(T-1),n)), np.eye(n*(T-1))])\n",
    "    C_tilde12 = np.kron(np.eye(T-1), B)\n",
    "    C_tilde21 = np.block([[np.eye(n), np.zeros((n,n*(T-1)))], \n",
    "                          [np.zeros((n,n*(T-1))), np.eye(n)]])\n",
    "    C_tilde22 = np.zeros((2 * n, m * (T-1)))\n",
    "\n",
    "    C_tilde = np.block([[C_tilde11, C_tilde12],\n",
    "                        [C_tilde21, C_tilde22]])\n",
    "\n",
    "    # construct dtilde\n",
    "    d_tilde = np.hstack([np.zeros(n * (T - 1)), x_init, x_des])\n",
    "    \n",
    "    return A_tilde, b_tilde, C_tilde, d_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "z-oga_Cqb6Ds"
   },
   "outputs": [],
   "source": [
    "# Here is some skeleton code to get you started.\n",
    "# Note that it will not run since we do not have some \n",
    "# of the values: C, n, T, rho for example\n",
    "# you will need to fill in some of the blanks\n",
    "x_init = np.array([0, 0, 0, 1])\n",
    "x_des = np.zeros(n)\n",
    "A_tilde, b_tilde, C_tilde, d_tilde = construct_tilde_matrices(A, B, C, x_init, \n",
    "                                                              x_des, T, rho)\n",
    "\n",
    "# once we have the tilde matrices, we will need to solve the \n",
    "# constrained least squares problem using KKT and rhs\n",
    "\n",
    "\n",
    "# plot your results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ORF307_HW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
